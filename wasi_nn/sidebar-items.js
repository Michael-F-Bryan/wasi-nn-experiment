initSidebarItems({"constant":[["EXECUTION_TARGET_CPU",""],["EXECUTION_TARGET_GPU",""],["EXECUTION_TARGET_TPU",""],["GRAPH_ENCODING_OPENVINO","TODO document buffer order"],["NN_ERRNO_BUSY","Device or resource busy."],["NN_ERRNO_INVALID_ARGUMENT","Caller module passed an invalid argument."],["NN_ERRNO_MISSING_MEMORY","Caller module is missing a memory export."],["NN_ERRNO_SUCCESS","No error occurred."],["TENSOR_TYPE_F16",""],["TENSOR_TYPE_F32",""],["TENSOR_TYPE_I32",""],["TENSOR_TYPE_U8",""]],"fn":[["compute","Compute the inference on the given inputs (see `set_input`)."],["get_output","Extract the outputs after inference."],["init_execution_context","TODO Functions like `describe_graph_inputs` and `describe_graph_outputs` (returning an array of `$tensor_description`s) might be useful for introspecting the graph but are not yet included here. Create an execution instance of a loaded graph. TODO this may need to accept flags that might affect the compilation or execution of the graph."],["load","Load an opaque sequence of bytes to use for inference."],["set_input","Define the inputs to use for inference."]],"mod":[["wasi_ephemeral_nn",""]],"struct":[["Error","A raw error returned by wasi-nn APIs, internally containing a 16-bit error code."],["Tensor",""]],"type":[["BufferSize",""],["ExecutionTarget",""],["Graph",""],["GraphBuilder",""],["GraphBuilderArray",""],["GraphEncoding",""],["GraphExecutionContext",""],["NnErrno",""],["Result",""],["TensorData",""],["TensorDimensions",""],["TensorType",""]]});